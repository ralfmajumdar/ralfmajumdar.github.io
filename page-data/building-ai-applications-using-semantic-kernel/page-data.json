{"componentChunkName":"component---node-modules-gatsby-theme-portfolio-minimal-src-templates-article-index-tsx","path":"/building-ai-applications-using-semantic-kernel/","result":{"pageContext":{"article":{"banner":{"alt":"","caption":"","src":null},"body":"<h2>Beyond the Prompt: Engineering Smarter AI with Semantic Kernel</h2>\n<p>As the adoption of Large Language Models (LLMs) grows, developers need a structured way to orchestrate prompts, manage AI skills, and integrate AI capabilities into software systems. This is where <strong>Semantic Kernel</strong> comes in - a powerful SDK from Microsoft that helps developers build AI-first apps using semantic functions, native code, and LLMs like OpenAI or Azure OpenAI.</p>\n<p>In this blog, we'll explore what Semantic Kernel is, how it works, and how you can use it to build scalable, modular, and context aware AI applications.</p>\n<hr>\n<h2>What is Semantic Kernel?</h2>\n<p><strong>Semantic Kernel (SK)</strong> is an <strong>open-source SDK</strong> that allows you to integrate <strong>AI services (like OpenAI GPT models)</strong> with <strong>traditional programming constructs</strong> such as functions, plugins, memory, and workflows.</p>\n<p>It is available in:</p>\n<ul>\n<li>C#</li>\n<li>Python</li>\n<li>Java (preview)</li>\n</ul>\n<p>With SK, you can combine <strong>semantic functions</strong> (prompt templates) and <strong>native functions</strong> (code-based logic) in one seamless pipeline—enabling <strong>hybrid AI systems</strong>.</p>\n<hr>\n<h2>Key Features</h2>\n<ul>\n<li><strong>Semantic functions</strong>: Use prompt engineering as first-class components</li>\n<li><strong>Pluggable AI models</strong>: Support for OpenAI, Azure OpenAI, Hugging Face, and more</li>\n<li><strong>Memory store</strong>: Persistent vector memory for context-aware reasoning</li>\n<li><strong>Planner</strong>: Auto-generates plans (sequences of steps) using AI</li>\n<li><strong>Skills architecture</strong>: Organize functions into reusable modules</li>\n</ul>\n<hr>\n<h2>How It Works</h2>\n<p>Here’s a simplified flow of a Semantic Kernel application:</p>\n<div class=\"gatsby-highlight\" data-language=\"plaintext\"><pre class=\"language-plaintext\"><code class=\"language-plaintext\">User Request\n     ↓\nSemantic Kernel\n     ↓\n[Semantic Functions + Native Functions + Memory + Planner]\n     ↓\nExternal LLM APIs (OpenAI, Azure OpenAI)\n     ↓\nResponse</code></pre></div>\n<p>You can define prompts (semantic functions), call native APIs (C#/Python code), retrieve memory from vector stores, and even generate plans automatically.</p>\n<h2>Installing Semantic Kernel (Python)</h2>\n<div class=\"gatsby-highlight\" data-language=\"py\"><pre class=\"language-py\"><code class=\"language-py\">pip install semantic<span class=\"token operator\">-</span>kernel</code></pre></div>\n<h2>Example: Build a Chatbot with Semantic Kernel</h2>\n<div class=\"gatsby-highlight\" data-language=\"py\"><pre class=\"language-py\"><code class=\"language-py\"><span class=\"token keyword\">import</span> semantic_kernel <span class=\"token keyword\">as</span> sk\n<span class=\"token keyword\">from</span> semantic_kernel<span class=\"token punctuation\">.</span>connectors<span class=\"token punctuation\">.</span>ai<span class=\"token punctuation\">.</span>open_ai <span class=\"token keyword\">import</span> OpenAIChatCompletion\n\n<span class=\"token comment\"># Create kernel</span>\nkernel <span class=\"token operator\">=</span> sk<span class=\"token punctuation\">.</span>Kernel<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\nkernel<span class=\"token punctuation\">.</span>add_chat_service<span class=\"token punctuation\">(</span>\n    <span class=\"token string\">\"chat-gpt\"</span><span class=\"token punctuation\">,</span>\n    OpenAIChatCompletion<span class=\"token punctuation\">(</span><span class=\"token string\">\"gpt-4\"</span><span class=\"token punctuation\">,</span> api_key<span class=\"token operator\">=</span><span class=\"token string\">\"YOUR_OPENAI_API_KEY\"</span><span class=\"token punctuation\">)</span>\n<span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\"># Create a semantic function from a prompt</span>\nprompt_template <span class=\"token operator\">=</span> <span class=\"token string\">\"You're a helpful assistant. Answer: {{$input}}\"</span>\nchat_function <span class=\"token operator\">=</span> kernel<span class=\"token punctuation\">.</span>create_semantic_function<span class=\"token punctuation\">(</span>prompt_template<span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\"># Run the function</span>\noutput <span class=\"token operator\">=</span> chat_function<span class=\"token punctuation\">(</span><span class=\"token string\">\"What is Semantic Kernel?\"</span><span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>output<span class=\"token punctuation\">)</span></code></pre></div>\n<h2>Using Semantic Functions and Native Functions Together</h2>\n<p>You can define a semantic skill using a .txt prompt file and then call it from Python or C#. Native functions (like API calls or math logic) can be registered as well.</p>\n<p>Example: Mixing prompts and Python logic:</p>\n<div class=\"gatsby-highlight\" data-language=\"py\"><pre class=\"language-py\"><code class=\"language-py\"><span class=\"token keyword\">def</span> <span class=\"token function\">get_user_name</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">-</span><span class=\"token operator\">></span> <span class=\"token builtin\">str</span><span class=\"token punctuation\">:</span>\n    <span class=\"token keyword\">return</span> <span class=\"token string\">\"Rahul\"</span>\n\nkernel<span class=\"token punctuation\">.</span>register_python_function<span class=\"token punctuation\">(</span>get_user_name<span class=\"token punctuation\">,</span> <span class=\"token string\">\"user_skill\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"get_user_name\"</span><span class=\"token punctuation\">)</span></code></pre></div>\n<h2>Adding Memory (Vector Store Integration)</h2>\n<p>Semantic Kernel supports:</p>\n<ul>\n<li>Volatile memory (in-memory)</li>\n<li>Persistent memory with plugins like:\n<ol>\n<li>Azure Cognitive Search</li>\n<li>Pinecone</li>\n<li>Redis</li>\n</ol>\n</li>\n</ul>\n<p>Add memory to your kernel:</p>\n<div class=\"gatsby-highlight\" data-language=\"py\"><pre class=\"language-py\"><code class=\"language-py\"><span class=\"token keyword\">from</span> semantic_kernel<span class=\"token punctuation\">.</span>memory<span class=\"token punctuation\">.</span>memory_store_base <span class=\"token keyword\">import</span> MemoryStoreBase\nkernel<span class=\"token punctuation\">.</span>register_memory_store<span class=\"token punctuation\">(</span>MyCustomVectorStore<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span></code></pre></div>\n<p>then:</p>\n<ul>\n<li>Store summaries, documents, chat history</li>\n<li>Query memory for relevant context</li>\n<li>Automatically ground LLM responses with context</li>\n</ul>\n<h2>Using the Planner for Auto-Generated Workflows</h2>\n<p>The Planner uses LLMs to generate step-by-step workflows (plans) based on user intent.</p>\n<div class=\"gatsby-highlight\" data-language=\"py\"><pre class=\"language-py\"><code class=\"language-py\">planner <span class=\"token operator\">=</span> SequentialPlanner<span class=\"token punctuation\">(</span>kernel<span class=\"token punctuation\">)</span>\nplan <span class=\"token operator\">=</span> planner<span class=\"token punctuation\">.</span>create_plan<span class=\"token punctuation\">(</span><span class=\"token string\">\"Translate this text and summarize it in one line.\"</span><span class=\"token punctuation\">)</span></code></pre></div>\n<p>This is useful for:</p>\n<ul>\n<li>Task chaining</li>\n<li>Intelligent agents</li>\n<li>Zero-shot orchestration</li>\n</ul>\n<h2>Architecture Overview</h2>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">                      ┌────────────┐\n   ┌──────────────┐   │ Semantic   │\n   │ User Input   ├──►│  Kernel    ├──┐\n   └──────────────┘   └────┬───────┘  │\n                           ▼          ▼\n         ┌────────┐  ┌──────────┐ ┌──────────┐\n         │ Prompt │  │  Memory  │ │  Native  │\n         │Engine  │  │ (Vector) │ │ Function │\n         └────────┘  └──────────┘ └──────────┘\n                           ▼\n                   External LLM (e.g., GPT-4)</code></pre></div>\n<h2>Use Cases for Semantic Kernel</h2>\n<ul>\n<li><b>AI copilots</b>: Embed AI into productivity tools (e.g., Office, VS Code)</li>\n<li><b>Multi-step agents</b>: Automate goal-driven behavior with planning</li>\n<li><b>Conversational AI</b>: Build advanced chatbots with memory and context</li>\n<li><b>RAG systems</b>: Retrieve content and augment prompts dynamically</li>\n<li><b>Data enrichment</b>: Combine AI and native logic to tag, summarize, classify</li>\n</ul>\n<h2>Further deep-dive</h2>\n<ul>\n<li><u><a href=\"https://github.com/microsoft/semantic-kernel\">GitHub: Semantic Kernel</a></u></li>\n</ul>\n<hr>\nAuthor: <br/>\n<u><a href=\"https://www.linkedin.com/in/rahul-majumdar/\">Rahul Majumdar</a></u>","categories":["AI","Semantic Kernel"],"date":"February 10, 2025","description":"Beyond the Prompt: Engineering Smarter AI with Semantic Kernel","id":"bc3ae7a3-33f3-5742-918e-de6f5784ab7a","keywords":["Artificial Intelligence","System Design","System Architecture"],"slug":"/building-ai-applications-using-semantic-kernel/","title":"Hands-On AI Orchestration with Semantic Kernel","readingTime":{"text":"4 min read"}},"listingPagePath":"/blog"}},"staticQueryHashes":["3262260831","948380417"],"slicesMap":{}}